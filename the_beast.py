import feedparser
import csv
import os
import requests
import re
import cloudscraper

SOURCES = [
    "https://nyaa.si/?page=rss",
    "https://www.tokyotosho.info/rss.php"
]
DB_FILE = 'database.csv'

def get_clean_hash_link(entry):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ù€ Hash Ù…Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙˆØªØ­ÙˆÙŠÙ„Ù‡ Ù„Ø±Ø§Ø¨Ø· Ù…Ø´Ø§Ù‡Ø¯Ø©"""
    # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø§ØºÙ†ÙŠØª ÙÙŠ Ø§Ù„Ø¥Ø¶Ø§ÙØ§Øª (Ø§Ù„Ù…Ø§ØºÙ†ÙŠØª ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø§Ù„Ù€ Hash)
    link = entry.link
    if hasattr(entry, 'nyaa_infohash'): # Ø®Ø§Øµ Ø¨Ù…ÙˆÙ‚Ø¹ Nyaa
        return f"https://webtor.io/player/embed/{entry.nyaa_infohash}"
    
    # Ù…Ø­Ø§ÙˆÙ„Ø© Ø¥ÙŠØ¬Ø§Ø¯ Ø§Ù„Ù€ Hash Ø¯Ø§Ø®Ù„ Ø§Ù„Ø±Ø§Ø¨Ø· Ù†ÙØ³Ù‡ Ø¥Ø°Ø§ ÙƒØ§Ù† Ù…Ø§ØºÙ†ÙŠØª
    hash_match = re.search(r'btih:([a-fA-F0-9]{40})', link)
    if hash_match:
        return f"https://webtor.io/player/embed/{hash_match.group(1).lower()}"
    
    return link

def translate_to_arabic(text):
    try:
        url = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl=en&tl=ar&dt=t&q={requests.utils.quote(text)}"
        res = requests.get(url, timeout=5)
        return res.json()[0][0][0]
    except:
        return text

def start_bot():
    database = {}
    # Ù…Ù„Ø§Ø­Ø¸Ø©: Ù„Ù† Ù†Ù‚Ø±Ø£ Ø§Ù„Ù…Ù„Ù Ø§Ù„Ù‚Ø¯ÙŠÙ… Ù‡Ø°Ù‡ Ø§Ù„Ù…Ø±Ø© Ù„Ø¶Ù…Ø§Ù† ØªØ­ÙˆÙŠÙ„ ÙƒÙ„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ù„Ù€ Hash
    scraper = cloudscraper.create_scraper()
    print("ğŸš€ Ø¬Ø§Ø±ÙŠ Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙˆØªØ­ÙˆÙŠÙ„Ù‡Ø§ Ø¥Ù„Ù‰ Hash Ù„Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø§Ù„Ù…Ø¨Ø§Ø´Ø±Ø©...")

    for rss_url in SOURCES:
        try:
            resp = scraper.get(rss_url, timeout=15)
            feed = feedparser.parse(resp.text)
            
            for entry in feed.entries[:30]:
                name_en = entry.title
                # ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ø±Ø§Ø¨Ø· Ø¥Ù„Ù‰ Hash Link ÙÙˆØ±Ø§Ù‹
                streaming_link = get_clean_hash_link(entry)
                
                if "webtor.io" in streaming_link: # Ù†Ø£Ø®Ø° ÙÙ‚Ø· Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„ØªÙŠ Ù†Ø¬Ø­ ØªØ­ÙˆÙŠÙ„Ù‡Ø§
                    name_ar = translate_to_arabic(name_en)
                    database[name_en] = {
                        'name_ar': name_ar,
                        'name_en': name_en,
                        'torrent_url': streaming_link,
                        'status': 'Ø¬Ø§Ù‡Ø² Ù„Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© ğŸ¿'
                    }
        except Exception as e:
            print(f"âŒ Ø®Ø·Ø£: {e}")

    with open(DB_FILE, 'w', newline='', encoding='utf-8') as f:
        fieldnames = ['name_ar', 'name_en', 'torrent_url', 'status']
        writer = csv.DictWriter(f, fieldnames=fieldnames)
        writer.writeheader()
        writer.writerows(database.values())
    print(f"âœ… ØªÙ… Ø§Ù„ØªØ­Ø¯ÙŠØ«! Ø§Ù„Ù…Ù„Ù Ø§Ù„Ø¢Ù† ÙŠØ­ØªÙˆÙŠ Ø¹Ù„Ù‰ Ø±ÙˆØ§Ø¨Ø· Hash ÙÙ‚Ø·.")

if __name__ == "__main__":
    start_bot()
