import feedparser
import csv
import requests
import re
import cloudscraper
import os

# Ù…ØµØ§Ø¯Ø± Ø§Ù„Ø£Ù†Ù…ÙŠ Ø§Ù„Ù…ØªØ±Ø¬Ù… Ù„Ù„Ø¹Ø±Ø¨ÙŠØ©
SOURCES = [
    "https://nyaa.si/?page=rss&q=Arabic+1080p",
    "https://nyaa.si/?page=rss&q=Arabic+720p",
    "https://nyaa.si/?page=rss&q=Arabic+480p",
    "https://www.tokyotosho.info/rss.php?filter=1,11&z=Arabic"
]

DB_FILE = 'database.csv'

def translate_to_arabic_only(text):
    """ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ø§Ø³Ù… Ù…Ù† Ø§Ù„Ø´ÙˆØ§Ø¦Ø¨ Ø§Ù„Ø¥Ù†Ø¬Ù„ÙŠØ²ÙŠØ© ÙˆØªØ±Ø¬Ù…ØªÙ‡"""
    # Ø­Ø°Ù Ø§Ù„ÙƒÙ„Ù…Ø§Øª Ø§Ù„ØªÙ‚Ù†ÙŠØ© ÙˆØ§Ù„Ø±Ù…ÙˆØ²
    clean_text = re.sub(r'\[.*?\]|\(.*?\)|1080p|720p|480p|HEVC|x264|x265|AAC|Vostfr|Multi', '', text).strip()
    try:
        url = f"https://translate.googleapis.com/translate_a/single?client=gtx&sl=auto&tl=ar&dt=t&q={requests.utils.quote(clean_text)}"
        res = requests.get(url, timeout=5)
        return res.json()[0][0][0]
    except:
        return clean_text

def get_clean_hash_link(entry):
    """Ø§Ø³ØªØ®Ø±Ø§Ø¬ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø´ØºÙ„ Ø§Ù„Ù…Ø¨Ø§Ø´Ø±"""
    if hasattr(entry, 'nyaa_infohash'):
        return f"https://webtor.io/player/embed/{entry.nyaa_infohash}"
    link = getattr(entry, 'link', '')
    hash_match = re.search(r'btih:([a-fA-F0-9]{40})', link)
    if hash_match:
        return f"https://webtor.io/player/embed/{hash_match.group(1).lower()}"
    return None

def start_bot():
    scraper = cloudscraper.create_scraper()
    print("ğŸ§¹ ØªÙ†Ø¸ÙŠÙ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ù‚Ø¯ÙŠÙ…Ø© ÙˆØ¬Ù„Ø¨ Ø£Ø­Ø¯Ø« Ø§Ù„Ø­Ù„Ù‚Ø§Øª...")

    # Ù†Ø³ØªØ®Ø¯Ù… dictionary Ù„Ù…Ù†Ø¹ Ø§Ù„ØªÙƒØ±Ø§Ø± (Ø§Ù„Ø§Ø³Ù… Ù‡Ùˆ Ø§Ù„Ù…ÙØªØ§Ø­)
    fresh_database = {}

    for rss_url in SOURCES:
        try:
            resp = scraper.get(rss_url, timeout=15)
            feed = feedparser.parse(resp.text)
            
            # Ù†Ø£Ø®Ø° Ø£ÙˆÙ„ 15 Ø­Ù„Ù‚Ø© ÙÙ‚Ø· Ù…Ù† ÙƒÙ„ Ù…ØµØ¯Ø± Ù„Ø¶Ù…Ø§Ù† Ø£Ù†Ù‡Ø§ "Ø¬Ø¯ÙŠØ¯Ø© Ø¬Ø¯Ø§Ù‹"
            for entry in feed.entries[:15]:
                link = get_clean_hash_link(entry)
                if link:
                    arabic_title = translate_to_arabic_only(entry.title)
                    
                    # Ø¬ÙˆØ¯Ø© Ø§Ù„ÙÙŠØ¯ÙŠÙˆ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠ
                    if "1080p" in entry.title: q = "1080p - FHD"
                    elif "720p" in entry.title: q = "720p - HD"
                    else: q = "480p - SD"
                    
                    # Ø­ÙØ¸ Ø¨Ø£Ø³Ù…Ø§Ø¡ Ø£Ø¹Ù…Ø¯Ø© Ø¹Ø±Ø¨ÙŠØ©
                    fresh_database[entry.title] = {
                        'Ø§Ø³Ù…_Ø§Ù„Ø£Ù†Ù…ÙŠ': arabic_title,
                        'Ø±Ø§Ø¨Ø·_Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø©': link,
                        'Ø§Ù„Ø¬ÙˆØ¯Ø©': q
                    }
        except:
            continue

    # Ø­ÙØ¸ Ø§Ù„Ù…Ù„Ù Ø¨ÙˆØ¶Ø¹ÙŠØ© 'w' Ù„Ù…Ø³Ø­ Ø§Ù„Ù‚Ø¯ÙŠÙ… ÙˆÙˆØ¶Ø¹ Ø§Ù„Ø¬Ø¯ÙŠØ¯ Ù„Ø¶Ù…Ø§Ù† Ø¹Ù…Ù„ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·
    with open(DB_FILE, 'w', newline='', encoding='utf-8') as f:
        columns = ['Ø§Ø³Ù…_Ø§Ù„Ø£Ù†Ù…ÙŠ', 'Ø±Ø§Ø¨Ø·_Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø©', 'Ø§Ù„Ø¬ÙˆØ¯Ø©']
        writer = csv.DictWriter(f, fieldnames=columns)
        writer.writeheader()
        writer.writerows(fresh_database.values())
    
    print(f"âœ… ØªÙ… ØªØ­Ø¯ÙŠØ« Ø§Ù„Ù…ÙƒØªØ¨Ø© Ø¨Ù€ {len(fresh_database)} Ø­Ù„Ù‚Ø© Ø¬Ø¯ÙŠØ¯Ø© ØªØ¹Ù…Ù„ Ø§Ù„Ø¢Ù†!")

if __name__ == "__main__":
    start_bot()
