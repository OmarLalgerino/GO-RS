import cloudscraper
from bs4 import BeautifulSoup
import csv
import re
import os

# Ø¥Ø¹Ø¯Ø§Ø¯ Ø§Ù„Ù‚Ù†Ø§Øµ
scraper = cloudscraper.create_scraper()

def get_video_links(page_url):
    """Ù‚Ù†Ø§Øµ Ø§Ù„Ø±ÙˆØ§Ø¨Ø·: ÙŠØ¨Ø­Ø« Ø¹Ù† MP4, MKV, M3U8 ÙˆØ§Ù„Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø¶Ù…Ù†Ø©"""
    links = {"1080p": "", "720p": "", "480p": ""}
    try:
        res = scraper.get(page_url, timeout=10)
        content = res.text
        
        # 1. Ø§Ù„Ø¨Ø­Ø« Ø§Ù„Ø´Ø§Ù…Ù„ Ø¹Ù† Ø¬Ù…ÙŠØ¹ ØµÙŠØº Ø§Ù„ÙÙŠØ¯ÙŠÙˆ (MP4, MKV, M3U8)
        # Ù†Ø³ØªØ®Ø¯Ù… Regex Ù„Ù…Ø³Ø­ Ø§Ù„ÙƒÙˆØ¯ Ø¨Ø§Ù„ÙƒØ§Ù…Ù„
        video_pattern = r'(https?://[^\s\'"]+\.(?:mp4|mkv|m3u8|webm)[^\s\'"]*)'
        found_videos = re.findall(video_pattern, content)
        
        if found_videos:
            for v_link in found_videos:
                # ÙÙ„ØªØ±Ø© Ø°ÙƒÙŠØ©: Ø¥Ø°Ø§ ÙˆØ¬Ø¯Ù†Ø§ mp4 Ùˆ mkv Ù„Ù†ÙØ³ Ø§Ù„Ø¬ÙˆØ¯Ø©ØŒ Ù†ÙØ¶Ù„ mp4 Ù„Ù„Ø³Ø±Ø¹Ø©
                v_lower = v_link.lower()
                if "1080" in v_lower or "fhd" in v_lower:
                    if not links["1080p"] or ".mp4" in v_lower: links["1080p"] = v_link
                elif "720" in v_lower or "hd" in v_lower:
                    if not links["720p"] or ".mp4" in v_lower: links["720p"] = v_link
                elif "480" in v_lower or "sd" in v_lower:
                    if not links["480p"] or ".mp4" in v_lower: links["480p"] = v_link

        # 2. Ø§Ù„Ø­Ù„ Ø§Ù„Ø¨Ø¯ÙŠÙ„: Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø´Ø§Ù‡Ø¯Ø© Ø£ÙˆÙ†Ù„Ø§ÙŠÙ† (Embed/Iframe)
        # Ø¥Ø°Ø§ Ù„Ù… Ù†Ø¬Ø¯ Ø±ÙˆØ§Ø¨Ø· Ù…Ø¨Ø§Ø´Ø±Ø©ØŒ Ù†Ø³Ø­Ø¨ Ø±Ø§Ø¨Ø· Ø§Ù„Ù…Ø´ØºÙ„
        if not links["720p"]:
            soup = BeautifulSoup(content, 'html.parser')
            iframes = soup.find_all('iframe', src=True)
            for ifrm in iframes:
                src = ifrm['src']
                if any(x in src for x in ['player', 'embed', 'mycima', 'vidoza']):
                    links["720p"] = src if src.startswith('http') else 'https:' + src
                    break

        return links
    except:
        return links

def update_database():
    source_url = "https://mycima.gold/category/series/%d9%85%d8%b3%d9%84%d8%b3%d9%84%d8%a7%d8%aa-%d8%aa%d8%b1%d9%83%d9%8a%d8%a9/"
    db_file = 'database.csv'
    all_data = []

    print(f"ğŸ” Ø¬Ø§Ø±ÙŠ ÙØ­Øµ Ø§Ù„Ù…ÙˆÙ‚Ø¹: {source_url}")
    try:
        res = scraper.get(source_url)
        soup = BeautifulSoup(res.content, 'html.parser')
        items = soup.find_all('div', class_='GridItem')

        for item in items[:20]: # ÙØ­Øµ Ø¢Ø®Ø± 20 Ø­Ù„Ù‚Ø© Ù…Ø¶Ø§ÙØ©
            title_tag = item.find('strong') or item.find('h2')
            name = title_tag.text.strip() if title_tag else "Ø­Ù„Ù‚Ø© Ø¬Ø¯ÙŠØ¯Ø©"
            link = item.find('a')['href']
            
            print(f"ğŸ“¡ Ø¬Ø§Ø±ÙŠ Ù‚Ù†Øµ (MP4/MKV/Online) Ù„Ù€: {name}")
            v_links = get_video_links(link)
            
            # Ø¥Ø¶Ø§ÙØ© ÙˆØ³Ù… Ù†ÙˆØ¹ Ø§Ù„Ø±Ø§Ø¨Ø· Ù„Ù„Ø§Ø³Ù… Ù„ØªÙ…ÙŠÙŠØ²Ù‡ ÙÙŠ ØªØ·Ø¨ÙŠÙ‚Ùƒ
            status = " (âœ… MP4)" if ".mp4" in str(v_links) else " (ğŸ“º Online)"
            
            all_data.append({
                'name': name + status,
                'url_1080p': v_links['1080p'],
                'url_720p': v_links['720p'],
                'url_480p': v_links['480p']
            })

        # Ø­ÙØ¸ Ø§Ù„Ù†ØªØ§Ø¦Ø¬ ÙÙŠ Ø§Ù„Ø¬Ø¯ÙˆÙ„
        with open(db_file, mode='w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['name', 'url_1080p', 'url_720p', 'url_480p'])
            writer.writeheader()
            writer.writerows(all_data)
        print("âœ¨ ØªÙ… ØªØ­Ø¯ÙŠØ« Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· Ø¨Ù†Ø¬Ø§Ø­!")
        
    except Exception as e:
        print(f"âŒ Ø­Ø¯Ø« Ø®Ø·Ø£: {e}")

if __name__ == "__main__":
    update_database()
