import cloudscraper
import re
import csv
from bs4 import BeautifulSoup

scraper = cloudscraper.create_scraper(browser={'browser': 'chrome','platform': 'android','desktop': False})

def get_streaming_player(url):
    """Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø±ÙˆØ§Ø¨Ø· Ø§Ù„Ù…Ø´ØºÙ„ (Embed) Ø¯Ø§Ø®Ù„ Ø§Ù„ØµÙØ­Ø©"""
    try:
        res = scraper.get(url, timeout=10)
        # Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ø³ÙŠØ±ÙØ±Ø§Øª: Dood, Uqload, Upstream, Vidoza
        pattern = r'https?://(?:doodstream\.com|dood\.to|dood\.so|uqload\.com|uqload\.co|upstream\.to|vidoza\.net)/[e|embed][^\s\'"<>]+'
        matches = re.findall(pattern, res.text)
        return matches[0] if matches else ""
    except:
        return ""

def update_big_database():
    # Ù‚Ø§Ø¦Ù…Ø© Ø¨Ù€ "Ù…Ù†Ø§Ø·Ù‚ Ø§Ù„ØµÙŠØ¯" (Ø£Ù‚Ø³Ø§Ù… Ø§Ù„Ù…Ø³Ù„Ø³Ù„Ø§Øª Ø§Ù„ØªØ±ÙƒÙŠØ© ÙÙŠ Ù…ÙˆØ§Ù‚Ø¹ Ù…Ø®ØªÙ„ÙØ©)
    hunting_zones = [
        "https://wecima.show/category/%d9%85%d8%b3%d9%84%d8%b3%d9%84%d8%a7%d8%aa-%d8%aa%d8%b1%d9%83%d9%8a%d8%a9/",
        "https://arabseed.show/category/Ù…Ø³Ù„Ø³Ù„Ø§Øª-ØªØ±ÙƒÙŠØ©/",
        "https://esheeq.org/",
        "https://4helau.tv/category/%d9%85%d8%b3%d9%84%d8%b3%d9%84%d8%a7%d8%aa-%d8%aa%d8%b1%d9%83%d9%8a%d8%a9-1/"
    ]
    
    all_episodes = []
    db_file = 'database.csv'

    for zone in hunting_zones:
        print(f"ğŸŒ Ø¬Ø§Ø±ÙŠ Ù…Ø³Ø­ Ø§Ù„Ù…Ù†Ø·Ù‚Ø©: {zone}")
        try:
            res = scraper.get(zone, timeout=15)
            soup = BeautifulSoup(res.text, 'html.parser')
            
            # Ù…Ø­Ø§ÙˆÙ„Ø© Ø§Ù„Ø¹Ø«ÙˆØ± Ø¹Ù„Ù‰ Ø¬Ù…ÙŠØ¹ Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ÙÙŠ Ø§Ù„ØµÙØ­Ø© Ø§Ù„ØªÙŠ Ù‚Ø¯ ØªÙƒÙˆÙ† Ø­Ù„Ù‚Ø§Øª
            links = soup.find_all('a', href=True)
            
            count = 0
            for link in links:
                if count >= 30: break # Ø³Ø­Ø¨ 30 Ø­Ù„Ù‚Ø© Ù…Ù† ÙƒÙ„ Ù…ÙˆÙ‚Ø¹ (Ø§Ù„Ø¥Ø¬Ù…Ø§Ù„ÙŠ 120 Ø­Ù„Ù‚Ø©)
                
                href = link['href']
                title = link.text.strip()
                
                # Ø§Ù„ØªØ£ÙƒØ¯ Ø£Ù† Ø§Ù„Ø±Ø§Ø¨Ø· ÙŠØ®Øµ Ø­Ù„Ù‚Ø© (ØªØµÙÙŠØ© Ø§Ù„Ø±ÙˆØ§Ø¨Ø· ØºÙŠØ± Ø§Ù„Ù…Ù‡Ù…Ø©)
                if "Ø­Ù„Ù‚Ø©" in title or "episode" in title.lower():
                    print(f"ğŸ” ÙØ­Øµ Ø§Ù„Ø³ÙŠØ±ÙØ± Ù„Ù€: {title}")
                    player = get_streaming_player(href)
                    
                    if player:
                        all_episodes.append({'name': title, 'player_url': player})
                        count += 1
                        print(f"âœ… ØªÙ… Ø§Ù„Ù‚Ù†Øµ!")

        except Exception as e:
            print(f"âš ï¸ ÙØ´Ù„ Ø¯Ø®ÙˆÙ„ Ø§Ù„Ù…Ù†Ø·Ù‚Ø© {zone}: {e}")

    # Ø­ÙØ¸ ÙƒÙ„ Ø§Ù„ØµÙŠØ¯ ÙÙŠ Ù…Ù„Ù CSV ÙˆØ§Ø­Ø¯
    if all_episodes:
        with open(db_file, 'w', newline='', encoding='utf-8') as f:
            writer = csv.DictWriter(f, fieldnames=['name', 'player_url'])
            writer.writeheader()
            writer.writerows(all_episodes)
        print(f"âœ¨ Ù…Ø¨Ø±ÙˆÙƒ! Ù‚Ù…Øª Ø¨ØµÙŠØ¯ {len(all_episodes)} Ø­Ù„Ù‚Ø© Ø¨Ù†Ø¬Ø§Ø­.")

if __name__ == "__main__":
    update_big_database()
